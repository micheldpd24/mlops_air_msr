{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/dkcentral/99_repos/mlops_msr/notebooks'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/dkcentral/99_repos/mlops_msr'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir(\"..\")\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Accessing as micheldpd24\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Accessing as micheldpd24\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Initialized MLflow to track repo <span style=\"color: #008000; text-decoration-color: #008000\">\"micheldpd24/mlflow_tracking\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Initialized MLflow to track repo \u001b[32m\"micheldpd24/mlflow_tracking\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Repository micheldpd24/mlflow_tracking initialized!\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Repository micheldpd24/mlflow_tracking initialized!\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# initialize mlflow server on DagsHub\n",
    "import dagshub\n",
    "dagshub.init(repo_owner='micheldpd24', repo_name='mlflow_tracking', mlflow=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mSystem information\u001b[0m: Darwin Darwin Kernel Version 21.6.0: Mon Jun 24 00:56:10 PDT 2024; root:xnu-8020.240.18.709.2~1/RELEASE_X86_64\n",
      "\u001b[34mPython version\u001b[0m: 3.11.5\n",
      "\u001b[34mMLflow version\u001b[0m: 2.17.2\n",
      "\u001b[34mMLflow module location\u001b[0m: /Users/dkcentral/99_repos/mlops_msr/.venv/lib/python3.11/site-packages/mlflow/__init__.py\n",
      "\u001b[34mTracking URI\u001b[0m: https://dagshub.com/micheldpd24/mlflow_tracking.mlflow\n",
      "\u001b[34mRegistry URI\u001b[0m: https://dagshub.com/micheldpd24/mlflow_tracking.mlflow\n",
      "\u001b[34mMLflow environment variables\u001b[0m: \n",
      "  MLFLOW_TRACKING_PASSWORD: f19e5be9a7551a5779324d989a3e80bd393c6b63\n",
      "  MLFLOW_TRACKING_URI: https://dagshub.com/micheldpd24/mlflow_tracking.mlflow\n",
      "  MLFLOW_TRACKING_USERNAME: micheldpd24\n",
      "\u001b[34mMLflow dependencies\u001b[0m: \n",
      "  Flask: 3.0.3\n",
      "  Jinja2: 3.1.4\n",
      "  aiohttp: 3.10.10\n",
      "  alembic: 1.14.0\n",
      "  boto3: 1.35.36\n",
      "  botocore: 1.35.36\n",
      "  docker: 7.1.0\n",
      "  graphene: 3.4.1\n",
      "  gunicorn: 23.0.0\n",
      "  markdown: 3.7\n",
      "  matplotlib: 3.9.2\n",
      "  mlflow-skinny: 2.17.2\n",
      "  numpy: 2.1.3\n",
      "  pandas: 2.2.3\n",
      "  pyarrow: 17.0.0\n",
      "  pydantic: 2.9.2\n",
      "  scikit-learn: 1.5.2\n",
      "  scipy: 1.14.1\n",
      "  sqlalchemy: 2.0.36\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "mlflow.doctor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.common_utils import read_yaml, create_directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.config import CONFIG_FILE_PATH, PARAMS_FILE_PATH, SCHEMA_FILE_PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Defining configuration classes for each stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### fichier entity.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass(frozen=True)\n",
    "class DataIngestionConfig:\n",
    "    root_dir: Path\n",
    "    source_url: str\n",
    "    local_data_file: Path\n",
    "    unzip_dir: Path\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class DataValidationConfig:\n",
    "    root_dir: Path\n",
    "    STATUS_FILE: str\n",
    "    unzip_data_dir: Path\n",
    "    all_schema: dict\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class DataTransformationConfig:\n",
    "    root_dir: Path\n",
    "    data_path: Path\n",
    "    reco_dir: Path\n",
    "    genres: list\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class ModelTrainerConfig:\n",
    "    root_dir: Path\n",
    "    X_train_path: Path\n",
    "    y_train_path: Path\n",
    "    X_test_path: Path\n",
    "    y_test_path: Path\n",
    "    model_name: str\n",
    "    learning_rate: float\n",
    "    max_depth: int\n",
    "    n_estimators: int\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class ModelEvaluationConfig:\n",
    "    root_dir: Path\n",
    "    X_test_path: Path\n",
    "    y_test_path: Path\n",
    "    model_path: Path\n",
    "    metric_file_name: Path\n",
    "    all_params: dict\n",
    "    mlflow_uri: str\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class UnsModelFitConfig:\n",
    "    root_dir: Path\n",
    "    features_path_prefix: str\n",
    "    genres_path: Path\n",
    "    model_dir: Path\n",
    "    model_name_prefix: str\n",
    "    metrics_path_prefix: str\n",
    "    all_params: dict\n",
    "    mlflow_uri: str\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Creation of a configuration manager which will create the configuration objects of each class for each step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### config_manager.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(\n",
    "        self,\n",
    "        config_filepath = CONFIG_FILE_PATH,\n",
    "        params_filepath = PARAMS_FILE_PATH,\n",
    "            schema_filepath = SCHEMA_FILE_PATH):\n",
    "\n",
    "            self.config = read_yaml(config_filepath)\n",
    "            self.params = read_yaml(params_filepath)\n",
    "            self.schema = read_yaml(schema_filepath)\n",
    "\n",
    "            \n",
    "    def get_data_ingestion_config(self) -> DataIngestionConfig:\n",
    "          config = self.config.data_ingestion\n",
    "\n",
    "          create_directories([config.root_dir])\n",
    "\n",
    "          data_ingestion_config = DataIngestionConfig(\n",
    "                root_dir= config.root_dir,\n",
    "                source_url=config.source_URL,\n",
    "                local_data_file=config.local_data_file,\n",
    "                unzip_dir=config.unzip_dir\n",
    "          )\n",
    "\n",
    "          return data_ingestion_config\n",
    "    \n",
    "    def get_data_validation_config(self) -> DataValidationConfig:\n",
    "        config = self.config.data_validation\n",
    "        schema = self.schema.COLUMNS\n",
    "\n",
    "        create_directories([config.root_dir])\n",
    "\n",
    "        data_validation_config = DataValidationConfig(\n",
    "            root_dir = config.root_dir,\n",
    "            STATUS_FILE = config.STATUS_FILE,\n",
    "            unzip_data_dir = config.unzip_dir,\n",
    "            all_schema = schema,\n",
    "        )\n",
    "\n",
    "        return data_validation_config\n",
    "    \n",
    "    def get_data_transformation_config(self) -> DataTransformationConfig:\n",
    "          config = self.config.data_transformation\n",
    "\n",
    "          create_directories([config.root_dir])\n",
    "          create_directories([config.reco_dir])\n",
    "\n",
    "          data_transformation_config = DataTransformationConfig(\n",
    "                root_dir = config.root_dir,\n",
    "                data_path =  config.data_path,\n",
    "                reco_dir = config.reco_dir,\n",
    "                genres = config.genres\n",
    "          )\n",
    "\n",
    "          return data_transformation_config\n",
    "    \n",
    "    def get_model_trainer_config(self) -> ModelTrainerConfig:\n",
    "          config = self.config.model_trainer\n",
    "          params = self.params.GradientBoostingClassifier\n",
    "          \n",
    "          create_directories([config.root_dir])\n",
    "\n",
    "          model_trainer_config = ModelTrainerConfig(\n",
    "                root_dir = config.root_dir,\n",
    "                X_train_path = config.X_train_path,\n",
    "                y_train_path = config.y_train_path,\n",
    "                X_test_path = config.X_test_path,\n",
    "                y_test_path = config.y_test_path,\n",
    "                model_name = config.model_name,\n",
    "                learning_rate = params.learning_rate,\n",
    "                max_depth = params.max_depth,\n",
    "                n_estimators = params.n_estimators\n",
    "          )\n",
    "\n",
    "          return model_trainer_config\n",
    "    \n",
    "    def get_model_evaluation_config(self) -> ModelEvaluationConfig:\n",
    "          config = self.config.model_evaluation\n",
    "          params = self.params.GradientBoostingClassifier\n",
    "\n",
    "          create_directories([config.root_dir])\n",
    "          \n",
    "          model_evaluation_config = ModelEvaluationConfig(\n",
    "                root_dir=config.root_dir,\n",
    "                X_test_path = config.X_test_path,\n",
    "                y_test_path = config.y_test_path,\n",
    "                model_path=config.model_path,\n",
    "                metric_file_name=config.metric_file_name,\n",
    "                all_params=params,\n",
    "                mlflow_uri=\"https://dagshub.com/micheldpd24/mlflow_tracking.mlflow\", # make sure to update this information\n",
    "          )\n",
    "\n",
    "          return model_evaluation_config\n",
    "    \n",
    "    def get_unsmodel_fit_config(self) -> UnsModelFitConfig:\n",
    "          config = self.config.unsmodel_fit\n",
    "          params = self.params.GaussianMixture\n",
    "          \n",
    "          create_directories([config.root_dir])\n",
    "\n",
    "          unsmodel_fit_config = UnsModelFitConfig(\n",
    "                root_dir = config.root_dir,\n",
    "                features_path_prefix = config.features_path_prefix,\n",
    "                genres_path = config.genres_path,\n",
    "                model_dir = config.model_dir,\n",
    "                model_name_prefix = config.model_name_prefix,\n",
    "                metrics_path_prefix = config.metrics_path_prefix,\n",
    "                all_params=params,\n",
    "                mlflow_uri=\"https://dagshub.com/micheldpd24/mlflow_tracking.mlflow\" # make sure to update this information\n",
    "          )\n",
    "\n",
    "          return unsmodel_fit_config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Creation of each module for each step using their configuration class to instantiate them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Ingestion step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request as request\n",
    "import os\n",
    "from pathlib import Path\n",
    "from custom_logger import logger\n",
    "import zipfile\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import shutil\n",
    "from src.common_utils import move_file_to_archives, delete_csv_files\n",
    "\n",
    "class DataIngestion:\n",
    "    def __init__(self, config: DataIngestionConfig):\n",
    "        self.config = config\n",
    "        \n",
    "    def download_file(self):\n",
    "        if not os.path.exists(self.config.local_data_file):\n",
    "            filename, headers = request.urlretrieve(\n",
    "                url = self.config.source_url,\n",
    "                filename = self.config.local_data_file\n",
    "            )\n",
    "            logger.info(f\"{filename} download! With following info: \\n{headers}\")\n",
    "        \n",
    "        else:\n",
    "            logger.info(f\"File already exists.\")\n",
    "\n",
    "    def extract_zip_file(self):\n",
    "        \"\"\"\n",
    "        zip_file_path: str\n",
    "        Extracts the zip file into the data directory\n",
    "        Function returns None\n",
    "        \"\"\"\n",
    "\n",
    "        unzip_path = self.config.unzip_dir\n",
    "        os.makedirs(unzip_path, exist_ok=True)\n",
    "        with zipfile.ZipFile(self.config.local_data_file, 'r') as zip_ref:\n",
    "            zip_ref.extractall(unzip_path)\n",
    "    \n",
    "    def make_data(self):\n",
    "        unzip_path = self.config.unzip_dir\n",
    "        raw_data_path = os.path.join(unzip_path, \"dataset.csv\")\n",
    "        \n",
    "        try:\n",
    "            df0 = pd.read_csv(raw_data_path, index_col=0)\n",
    "        except FileNotFoundError as e:\n",
    "            logger.error(f\"Raw data file not found at {raw_data_path}: {e}\")\n",
    "            return\n",
    "        \n",
    "        df0.rename(columns={\"track_id\": \"uri\",  \"track_genre\": \"genre\"}, inplace=True)\n",
    "        \n",
    "        columns_to_drop = [\"artists\", \"album_name\", \"track_name\", \"popularity\", \"explicit\", \n",
    "                           \"time_signature\", \"duration_ms\", \"mode\", \"liveness\"]\n",
    "        \n",
    "        df0.drop(columns=columns_to_drop, axis=1, inplace=True)\n",
    "        df0.dropna(inplace=True, ignore_index=True)\n",
    "        \n",
    "        genres = ['alternative', 'classical', 'country', 'edm', 'hip-hop', \n",
    "                  'jazz', 'latin', 'pop', 'r-n-b', 'rock']\n",
    "        \n",
    "        df = df0[df0[\"genre\"].isin(genres)].reset_index(drop=True)\n",
    "        df.drop_duplicates(subset=[\"uri\"], inplace=True, ignore_index=True)\n",
    "\n",
    "        logger.info(f\"Dataset shape after processing: {df.shape}\")\n",
    "        logger.info(f\"First few records:\\n{df.head()}\")\n",
    "\n",
    "        df.to_csv(\"data/raw/song_df.csv\")\n",
    "\n",
    "\n",
    "    def get_data(self):\n",
    "        \"\"\"Main function to trigger the download, extraction, and data processing.\"\"\"\n",
    "        \n",
    "        # check if song_df exists in \"data/raw\"\n",
    "        path_file = os.path.join(self.config.root_dir, \"song_df.csv\")\n",
    "        if Path(path_file).exists():\n",
    "            print(\"Retraining mode - No need to download and extract the dataset again.\")\n",
    "            logger.info(\"Retraining mode - No need to download and extract the dataset again.\")\n",
    "        else:\n",
    "            print(\"Extracting and preparing dataset\")\n",
    "            logger.info(\"Extracting and preparing dataset\")  \n",
    "            self.download_file()\n",
    "            self.extract_zip_file()\n",
    "            self.make_data()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Validation step  -> data_validation.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from src.config_manager import DataValidationConfig\n",
    "\n",
    "class DataValidation:\n",
    "    def __init__(self, config: DataValidationConfig):\n",
    "        self.config = config\n",
    "\n",
    "    def validate_all_columns(self) -> bool:\n",
    "        try:\n",
    "            validation_status = None\n",
    "            data = pd.read_csv(self.config.unzip_data_dir)\n",
    "            all_cols = list(data.columns)\n",
    "\n",
    "            all_schema = self.config.all_schema.keys()\n",
    "\n",
    "            for col in all_cols:\n",
    "                if col not in all_schema:\n",
    "                    validation_status = False\n",
    "                    with open(self.config.STATUS_FILE, 'w') as f:\n",
    "                        f.write(f\"Validation status: {validation_status}\")\n",
    "                else:\n",
    "                    validation_status =  True\n",
    "                    with open(self.config.STATUS_FILE, 'w') as f:\n",
    "                        f.write(f\"Validation status: {validation_status}\")\n",
    "            return validation_status\n",
    "        except Exception as e:\n",
    "            raise e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Transformation step --> data_transformation.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from custom_logger import logger\n",
    "from src.entity import DataTransformationConfig\n",
    "\n",
    "class DataTransformation:\n",
    "    def __init__(self, config: DataTransformationConfig):\n",
    "        self.config = config\n",
    "\n",
    "    def train_test_splitting(self): \n",
    "        data = pd.read_csv(self.config.data_path, index_col=0)\n",
    "        # data = pd.read_csv(os.path.join(self.config.root_dir, \"data_scaled.csv\"), index_col=0)\n",
    "\n",
    "        X = data.drop(columns=[\"uri\", \"genre\"])\n",
    "        y = data[\"genre\"]\n",
    "        check = pd.DataFrame()  # control\n",
    "        check[\"genre\"] = data[\"genre\"]  # control\n",
    "        \n",
    "        # Label encoder\n",
    "        le = LabelEncoder()\n",
    "        le.fit(y)\n",
    "        y = le.transform(y)\n",
    "        y = pd.DataFrame(y)\n",
    "        \n",
    "        check[\"label\"] = y  # control\n",
    "        print(check.value_counts())  # control\n",
    "        \n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "        X_train.to_csv(os.path.join(self.config.root_dir, \"X_train.csv\"), index = False)\n",
    "        y_train.to_csv(os.path.join(self.config.root_dir, \"y_train.csv\"), index = False)\n",
    "        X_test.to_csv(os.path.join(self.config.root_dir, \"X_test.csv\"), index = False)\n",
    "        y_test.to_csv(os.path.join(self.config.root_dir, \"y_test.csv\"), index = False)\n",
    "\n",
    "        logger.info(\"Splitted data into training and test datasets\")\n",
    "        logger.info(f\"X_train shape: {X_train.shape}, y_train shape: {y_train.shape}\")\n",
    "        logger.info(f\"X_test shape: {X_test.shape}, y_test shape: {y_test.shape}\")\n",
    "\n",
    "        print(X_train.shape, y_train.shape)\n",
    "        print(X_test.shape, y_test.shape)\n",
    "\n",
    "    # split data by music genre and save list of music genre into a txt file\n",
    "    def split_by_genre(self):\n",
    "        \n",
    "        data = pd.read_csv(self.config.data_path, index_col=0)\n",
    "        genres = self.config.genres\n",
    "\n",
    "        with open(os.path.join(self.config.reco_dir, \"genres.txt\"), \"w\") as f:\n",
    "            f.write(\"\\n\".join(genres))\n",
    "        \n",
    "        logger.info(f\"List of music genres savec into genre.txt\")\n",
    "\n",
    "        for i, genre in enumerate(genres):\n",
    "            data_genre = data[data[\"genre\"] == genre]\n",
    "            data_genre = data_genre.drop(columns = [\"genre\"]).reset_index(drop=True)\n",
    "            data_genre.to_csv(os.path.join(self.config.reco_dir, f\"to_rec_{i}.csv\"), index = False)\n",
    "            \n",
    "            logger.info(f\"{genre} music data extracted\")\n",
    "            logger.info(f\"{genre}_data shape: {data_genre.shape}\")\n",
    "    \n",
    "        logger.info(f\"Songs data splitted by music genres\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Trainer step  --> model_trainer.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from src.entity import ModelTrainerConfig\n",
    "\n",
    "class ModelTrainer:\n",
    "    def __init__(self, config: ModelTrainerConfig):\n",
    "        self.config = config\n",
    "\n",
    "    def train(self):\n",
    "        X_train = pd.read_csv(self.config.X_train_path)\n",
    "        y_train = pd.read_csv(self.config.y_train_path)\n",
    "        X_train = X_train.values\n",
    "        y_train = y_train.values.ravel()\n",
    "\n",
    "        # Define the pipeline min max scaling + grad boot clf\n",
    "        # min_max_trans = MinMaxScaler()  \n",
    "        model = GradientBoostingClassifier(\n",
    "            learning_rate=self.config.learning_rate,\n",
    "            max_depth=self.config.max_depth,\n",
    "            n_estimators=self.config.n_estimators,\n",
    "            random_state=42\n",
    "        )\n",
    "        # model = Pipeline(steps=[('t', min_max_trans), ('m', gb)])\n",
    "\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        joblib.dump(\n",
    "            model, os.path.join(\n",
    "                self.config.root_dir, \n",
    "                self.config.model_name\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Evaluation step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "from time import time\n",
    "import mlflow\n",
    "from mlflow import MlflowClient\n",
    "import mlflow.sklearn\n",
    "# import dagshub\n",
    "import joblib\n",
    "from urllib.parse import urlparse\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from src.entity import ModelEvaluationConfig\n",
    "from src.common_utils import save_json\n",
    "from mlflow.models import infer_signature\n",
    "\n",
    "# make sure to register to DagsHub and create you own repo\n",
    "# dagshub.init(repo_owner='micheldpd24', repo_name='mlops_music_recsys', mlflow=True)\n",
    "\n",
    "class ModelEvaluation:\n",
    "    def __init__(self, config: ModelEvaluationConfig):\n",
    "        self.config = config\n",
    "\n",
    "        \n",
    "    def eval_metrics(self, actual, pred):\n",
    "        accuracy = accuracy_score(actual, pred)\n",
    "        cl_report = classification_report(actual, pred)\n",
    "        \n",
    "        print(\"Classification Report:\")\n",
    "        print(cl_report)\n",
    "        \n",
    "        return accuracy\n",
    "    \n",
    "    def log_into_mlflow(self):\n",
    "        \n",
    "        X_test = pd.read_csv(self.config.X_test_path)\n",
    "        y_test = pd.read_csv(self.config.y_test_path)\n",
    "        \n",
    "        X_test = X_test.values\n",
    "        y_test = y_test.values.ravel()\n",
    "        \n",
    "        model = joblib.load(self.config.model_path)\n",
    "\n",
    "        mlflow.set_registry_uri(self.config.mlflow_uri)\n",
    "        # tracking_url_type_store = urlparse(mlflow.get_tracking_uri()).scheme\n",
    "\n",
    "        mlflow.set_experiment(experiment_name=\"music_clf\")\n",
    "        mlflow.set_experiment_tag('mlflow.note.content', \"Songs classification by music genre\")\n",
    "        \n",
    "        with mlflow.start_run():\n",
    "            t0 = time()\n",
    "            predicted_genres = model.predict(X_test)\n",
    "            time_predict = time() - t0\n",
    "\n",
    "            accuracy = self.eval_metrics(y_test, predicted_genres)\n",
    "\n",
    "            # Saving metrics\n",
    "            scores = {\"accuracy\": accuracy, \"time_predict\": time_predict}\n",
    "            save_json(path=Path(self.config.metric_file_name), data=scores)\n",
    "\n",
    "            mlflow.log_params(self.config.all_params)\n",
    "            mlflow.log_metric(\"accuracy\", accuracy)\n",
    "            mlflow.log_metric(\"time_predict\", time_predict)\n",
    "            signature = infer_signature(X_test, model.predict(X_test))\n",
    "            \n",
    "            print(\"*** starting log_model: Music Classification ***\")  # Control\n",
    "            # Model registry does not work with file store\n",
    "            \n",
    "            # control\n",
    "            # print(\"*** tracking_url_type_store *** :\\n\", tracking_url_type_store)\n",
    "            mlflow.sklearn.log_model(\n",
    "                    model, \n",
    "                    \"GB_model\", \n",
    "                    signature=signature\n",
    "            )\n",
    "\n",
    "\n",
    "            # if tracking_url_type_store != \"file\":\n",
    "            #     mlflow.sklearn.log_model(\n",
    "            #         model, \n",
    "            #         \"model\", \n",
    "            #         # registered_model_name=\"GradBoostClf\",\n",
    "            #         signature=signature\n",
    "            #     )\n",
    "            # else:\n",
    "            #     mlflow.sklearn.log_model(\n",
    "            #         model, \n",
    "            #         \"model\",\n",
    "            #         signature=signature\n",
    "            #     )\n",
    "            # print(\"*** en if else check ***\")  # control\n",
    "\n",
    "    def get_best_clf_model(self):\n",
    "        \"\"\"\n",
    "        Retrieves the MLflow run with the best score for a specified metric and loads the associated model.\n",
    "        \n",
    "        Args:\n",
    "            experiment_name (str): The name of the MLflow experiment.\n",
    "            metric (str): The metric used to determine the best model. Default is \"accuracy\".\n",
    "        \n",
    "        Returns:\n",
    "            tuple: A tuple containing:\n",
    "                - loaded_model: The MLflow model object.\n",
    "                - best_run_id (str): The ID of the best run.\n",
    "                - best_metric_value (float): The value of the best metric.\n",
    "        \n",
    "        Raises:\n",
    "            ValueError: If the experiment or runs are not found.\n",
    "        \"\"\"\n",
    "\n",
    "        experiment_name = \"music_clf\"\n",
    "        model = \"GB_model\"\n",
    "        metric = \"accuracy\"\n",
    "\n",
    "        # Initialize the MLflow client\n",
    "        client = MlflowClient()\n",
    "\n",
    "        # Get the experiment details\n",
    "        experiment = client.get_experiment_by_name(experiment_name)\n",
    "        if not experiment:\n",
    "            raise ValueError(f\"Experiment '{experiment_name}' not found!\")\n",
    "        \n",
    "        # Fetch all runs for the experiment\n",
    "        runs = client.search_runs(\n",
    "            experiment_ids=[experiment.experiment_id],\n",
    "            filter_string=\"\",\n",
    "            run_view_type=mlflow.entities.ViewType.ACTIVE_ONLY,\n",
    "            order_by=[f\"metrics.{metric} DESC\"]  # Order by the specified metric in descending order\n",
    "        )\n",
    "        \n",
    "        if not runs:\n",
    "            raise ValueError(f\"No runs found for experiment '{experiment_name}'!\")\n",
    "        \n",
    "        # Extract the best run\n",
    "        best_run = runs[0]\n",
    "        best_run_id = best_run.info.run_id\n",
    "        best_metric_value = best_run.data.metrics[metric]\n",
    "        \n",
    "        print(f\"Best Run ID: {best_run_id}\")\n",
    "        print(f\"Best {metric.capitalize()}: {best_metric_value}\")\n",
    "        \n",
    "        # Load the model associated with the best run\n",
    "        model_uri = f\"runs:/{best_run_id}/{model}\"\n",
    "        loaded_model = mlflow.pyfunc.load_model(model_uri)\n",
    "        \n",
    "        print(f\"Best {experiment_name} model loaded successfully!\")\n",
    "        \n",
    "        # save the model\n",
    "        best_model_path = \"models_best/gb_model.joblib\"\n",
    "        joblib.dump(loaded_model, best_model_path)\n",
    "\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        best_data = {\n",
    "            \"timestamp\": timestamp,\n",
    "            \"experiment_name\": experiment_name,\n",
    "            \"run_id\": best_run_id,\n",
    "            \"model\": model, \n",
    "            \"model_uri\": model_uri, \n",
    "            \"metric\": metric, \n",
    "            \"metric_value\": best_metric_value\n",
    "        }\n",
    "        best_data_path = os.path.join(\"data/models_best\", f\"{experiment_name}_best_model_{timestamp}.json\")\n",
    "        save_json(Path(best_data_path), best_data)\n",
    "        print(f\"Best {experiment_name} model saved successfully!\")\n",
    "        \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unsupervised Model Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from pathlib import Path\n",
    "from urllib.parse import urlparse\n",
    "from time import time\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from mlflow.models import infer_signature\n",
    "from mlflow.pyfunc import PythonModel\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.metrics import (\n",
    "    silhouette_score,\n",
    "    calinski_harabasz_score,\n",
    "    davies_bouldin_score\n",
    ")\n",
    "from src.entity import UnsModelFitConfig\n",
    "from src.common_utils import load_txt, save_json, delete_folder\n",
    "\n",
    "\n",
    "class UnsModelFit:\n",
    "    def __init__(self, config: UnsModelFitConfig):\n",
    "        self.config = config\n",
    "\n",
    "    def unsfit(self):\n",
    "        genres = load_txt(Path(self.config.genres_path))\n",
    "\n",
    "        class ModelWrapper(PythonModel):\n",
    "            def __init__(self):\n",
    "                self.model = None\n",
    "\n",
    "\n",
    "            def load_context(self, context):\n",
    "                from joblib import load\n",
    "                self.model = load(context.artifacts[\"model_path\"])\n",
    "\n",
    "            def predict(self, context, model_input, params=None):\n",
    "                params = params or {\"predict_method\": \"predict\"}\n",
    "                predict_method = params.get(\"predict_method\")\n",
    "\n",
    "                if predict_method == \"predict\":\n",
    "                    return self.model.predict(model_input)\n",
    "                elif predict_method == \"predict_proba\":\n",
    "                    return self.model.predict_proba(model_input)\n",
    "                elif predict_method == \"predict_log_proba\":\n",
    "                    return self.model.predict_log_proba(model_input)\n",
    "                else:\n",
    "                    raise ValueError(f\"The prediction method '{predict_method}' is not supported.\")\n",
    "\n",
    "        for element, genre in enumerate(genres):\n",
    "            try:\n",
    "                # Load feature file\n",
    "                features_path = Path(self.config.features_path_prefix+f\"{element}.csv\")\n",
    "                if not features_path.exists():\n",
    "                    print(f\"File not found: {features_path}\")\n",
    "                    continue  # Skip this iteration if the file does not exist\n",
    "                \n",
    "                features = pd.read_csv(features_path)\n",
    "                features = features.drop(columns=[\"uri\"], errors=\"ignore\")\n",
    "                features = features.values\n",
    "                \n",
    "                # Initialize Gaussian Mixture Model\n",
    "                model = GaussianMixture(\n",
    "                    n_components=self.config.all_params.n_components[element],\n",
    "                    covariance_type=self.config.all_params.covariance_type,\n",
    "                    random_state=self.config.all_params.random_state\n",
    "                )\n",
    "\n",
    "                # Fit the model\n",
    "                model.fit(features)\n",
    "                \n",
    "                # Save raw model\n",
    "                \n",
    "                model_filename = f\"{self.config.model_name_prefix}{element}.joblib\"\n",
    "                model_path = os.path.join(self.config.root_dir, model_filename)\n",
    "    \n",
    "                joblib.dump(model, model_path)  # save the model to a .joblib file\n",
    "\n",
    "                # Define artifacts for wrapped model\n",
    "                artifacts = {\"model_path\": model_path}\n",
    "\n",
    "                # Save wrapped PyFunc model\n",
    "                pyfunc_path = f\"models/pyfunc_gm_model_{element}\"\n",
    "                signature = infer_signature(features, params={\"predict_method\": \"predict_proba\"}) \n",
    "                mlflow.set_registry_uri(self.config.mlflow_uri)\n",
    "                tracking_url_type_store = urlparse(mlflow.get_tracking_uri()).scheme\n",
    "                mlflow.set_experiment(experiment_name=f\"clst_{element}_{genre}\")\n",
    "                mlflow.set_experiment_tag('mlflow.note.content', f\"Clustering {genre} songs with Gaussian Mixture Model\")\n",
    "\n",
    "                delete_folder(pyfunc_path)\n",
    "                with mlflow.start_run():\n",
    "                    mlflow.pyfunc.save_model(\n",
    "                        path=pyfunc_path,\n",
    "                        python_model=ModelWrapper(),\n",
    "                        input_example=features,\n",
    "                        signature=signature,\n",
    "                        artifacts=artifacts,\n",
    "                        pip_requirements=[\"joblib\", \"sklearn\"],\n",
    "                    )\n",
    "\n",
    "                    wrapped_model= mlflow.pyfunc.load_model(pyfunc_path)\n",
    "\n",
    "                    # Save the fitted model\n",
    "                    model_path = os.path.join(\n",
    "                                    self.config.root_dir, \n",
    "                                    self.config.model_name_prefix+f\"{element}.joblib\"\n",
    "                    )\n",
    "                    joblib.dump(model, model_path)\n",
    "\n",
    "                    # Prediction and metrics\n",
    "                    t0 = time()\n",
    "                    prediction = wrapped_model.predict(features, params={\"predict_method\": \"predict\"})\n",
    "                    time_predict = time() - t0\n",
    "                    \n",
    "                    \n",
    "                    silh_score = silhouette_score(features, prediction)\n",
    "                    chi_score = calinski_harabasz_score(features, prediction)\n",
    "                    dab_score = davies_bouldin_score(features, prediction)\n",
    "\n",
    "                    scores = {\n",
    "                        \"silhouette_score\": silh_score,\n",
    "                        \"calinski_harabasz_score\": chi_score,\n",
    "                        \"davies_bouldin_score\": dab_score,\n",
    "                        \"time_predict\": time_predict\n",
    "                    }\n",
    "\n",
    "                    metrics_file_path = Path(f\"{self.config.metrics_path_prefix}{element}.json\")\n",
    "                    save_json(metrics_file_path, data=scores)\n",
    "\n",
    "                    # Log metrics and parameters\n",
    "                    model_params = {\n",
    "                        \"n_components\": self.config.all_params.n_components[element],\n",
    "                        \"covariance_type\": self.config.all_params.covariance_type,\n",
    "                        \"random_state\": self.config.all_params.random_state\n",
    "                    }\n",
    "                    \n",
    "                    mlflow.log_params(model_params)\n",
    "                    mlflow.log_metric(\"silhouette_score\", silh_score)\n",
    "                    mlflow.log_metric(\"calinski_harabasz_score\", chi_score)\n",
    "                    mlflow.log_metric(\"davies_bouldin_score\", dab_score)\n",
    "                    mlflow.log_metric(\"time_predict\", time_predict)\n",
    "                    signature = infer_signature(features, wrapped_model.predict(features)) \n",
    "                    \n",
    "                    mlflow.sklearn.log_model(\n",
    "                                wrapped_model, \n",
    "                                \"GM_model\", \n",
    "                                signature=signature,\n",
    "                    )\n",
    "                    print(f\"Logged model for {genre}: {element}\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error in processing element {element}: {e}\")\n",
    "            \n",
    "    def get_best_clst_model(self):\n",
    "        \"\"\"\n",
    "        Retrieves the MLflow run with the best score for a specified metric and loads the associated model.\n",
    "        \n",
    "        Args:\n",
    "            experiment_name (str): The name of the MLflow experiment.\n",
    "            metric (str): The metric used to determine the best model. Default is \"accuracy\".\n",
    "        \n",
    "        Raises:\n",
    "            ValueError: If the experiment or runs are not found.\n",
    "        \"\"\"\n",
    "\n",
    "        genres = load_txt(Path(self.config.genres_path))\n",
    "        \n",
    "        # Initialize the MLflow client\n",
    "        client = MlflowClient()\n",
    "\n",
    "        for element, genre in enumerate(genres):\n",
    "            \n",
    "            experiment_name = f\"clst_{element}_{genre}\"\n",
    "            model = \"GM_model\"\n",
    "            metric = \"silhouette_score\"\n",
    "\n",
    "            # Get the experiment details\n",
    "            experiment = client.get_experiment_by_name(experiment_name)\n",
    "            if not experiment:\n",
    "                raise ValueError(f\"Experiment '{experiment_name}' not found!\")\n",
    "            \n",
    "            # Fetch all runs for the experiment\n",
    "            runs = client.search_runs(\n",
    "                experiment_ids=[experiment.experiment_id],\n",
    "                filter_string=\"\",\n",
    "                run_view_type=mlflow.entities.ViewType.ACTIVE_ONLY,\n",
    "                order_by=[f\"metrics.{metric} DESC\"]  # Order by the specified metric in descending order\n",
    "            )\n",
    "            \n",
    "            if not runs:\n",
    "                raise ValueError(f\"No runs found for experiment '{experiment_name}'!\")\n",
    "            \n",
    "            # Extract the best run\n",
    "            best_run = runs[0]\n",
    "            best_run_id = best_run.info.run_id\n",
    "            best_metric_value = best_run.data.metrics[metric]\n",
    "            \n",
    "            print(f\"Best Run ID: {best_run_id}\")\n",
    "            print(f\"Best {metric.capitalize()}: {best_metric_value}\")\n",
    "            \n",
    "            # Load the model associated with the best run\n",
    "            model_uri = f\"runs:/{best_run_id}/{model}\"\n",
    "            loaded_model = mlflow.pyfunc.load_model(model_uri)\n",
    "            \n",
    "            print(f\"Best {experiment_name} model loaded successfully!\")\n",
    "\n",
    "            # save the model\n",
    "            best_model_path = Path(f\"models_best/gm_model_{element}\")\n",
    "            delete_folder(best_model_path)\n",
    "            mlflow.sklearn.save_model(loaded_model, best_model_path)\n",
    "            \n",
    "            timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "            best_data = {\n",
    "                \"timestamp\": timestamp,\n",
    "                \"experiment_name\": experiment_name,\n",
    "                \"run_id\": best_run_id,\n",
    "                \"model\": model, \n",
    "                \"model_uri\": model_uri, \n",
    "                \"metric\": metric, \n",
    "                \"metric_value\": best_metric_value\n",
    "            }\n",
    "            save_json(Path(f\"data/models_best/{experiment_name}_best_{timestamp}.json\"), best_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Pipeline steps to instantiate the classes and call each process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Ingestion step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retraining mode - No need to download and extract the dataset again.\n"
     ]
    }
   ],
   "source": [
    "config = ConfigurationManager()\n",
    "data_ingestion_config = config.get_data_ingestion_config()\n",
    "data_ingestion = DataIngestion(config = data_ingestion_config)\n",
    "# data_ingestion.download_file()\n",
    "# data_ingestion.extract_zip_file()\n",
    "# data_ingestion.make_data()\n",
    "data_ingestion.get_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Validation step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = ConfigurationManager()\n",
    "data_validation_config = config.get_data_validation_config()\n",
    "data_validation = DataValidation(config=data_validation_config)\n",
    "data_validation.validate_all_columns()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Transformation step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***\n",
      "***\n",
      "genre        label\n",
      "edm          3        1003\n",
      "alternative  0         999\n",
      "jazz         5         999\n",
      "country      2         994\n",
      "hip-hop      4         991\n",
      "r-n-b        8         989\n",
      "classical    1         933\n",
      "latin        6         810\n",
      "pop          7         798\n",
      "rock         9         759\n",
      "Name: count, dtype: int64\n",
      "(7420, 9) (7420, 1)\n",
      "(1855, 9) (1855, 1)\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    with open(Path(\"data/status.txt\"), 'r') as f:\n",
    "        status = f.read().split(\" \")[-1]\n",
    "            \n",
    "    if status == \"True\":\n",
    "        config = ConfigurationManager()\n",
    "        print(\"***\")\n",
    "        data_transformation_config = config.get_data_transformation_config()\n",
    "        print(\"***\")\n",
    "        data_transformation = DataTransformation(config = data_transformation_config)\n",
    "        data_transformation.train_test_splitting()\n",
    "        data_transformation.split_by_genre()\n",
    "    else:\n",
    "        raise Exception(\"Your data schema is not valid\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model trainer step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = ConfigurationManager()\n",
    "model_trainer_config = config.get_model_trainer_config()\n",
    "model_trainer = ModelTrainer(config= model_trainer_config)\n",
    "model_trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model evaluation step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.63      0.59       195\n",
      "           1       0.88      0.85      0.86       191\n",
      "           2       0.56      0.66      0.60       192\n",
      "           3       0.65      0.70      0.67       199\n",
      "           4       0.63      0.60      0.61       204\n",
      "           5       0.73      0.76      0.75       203\n",
      "           6       0.73      0.69      0.71       177\n",
      "           7       0.58      0.49      0.53       152\n",
      "           8       0.47      0.43      0.45       195\n",
      "           9       0.80      0.67      0.73       147\n",
      "\n",
      "    accuracy                           0.65      1855\n",
      "   macro avg       0.66      0.65      0.65      1855\n",
      "weighted avg       0.65      0.65      0.65      1855\n",
      "\n",
      "*** starting log_model: Music Classification ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/17 20:46:00 INFO mlflow.tracking._tracking_service.client: üèÉ View run mysterious-horse-759 at: https://dagshub.com/micheldpd24/mlflow_tracking.mlflow/#/experiments/0/runs/c3861f0ad49a45a9b5133a154c2b93da.\n",
      "2024/11/17 20:46:00 INFO mlflow.tracking._tracking_service.client: üß™ View experiment at: https://dagshub.com/micheldpd24/mlflow_tracking.mlflow/#/experiments/0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Run ID: c3861f0ad49a45a9b5133a154c2b93da\n",
      "Best Accuracy: 0.6506738544474393\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a80f652c4a54f0d839a1d5b0cb75c15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best music_clf model loaded successfully!\n",
      "Best music_clf model saved successfully!\n"
     ]
    }
   ],
   "source": [
    "config = ConfigurationManager()\n",
    "model_evaluation_config = config.get_model_evaluation_config()\n",
    "model_evaluation = ModelEvaluation(config = model_evaluation_config)\n",
    "model_evaluation.log_into_mlflow()\n",
    "model_evaluation.get_best_clf_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unsupervised Model Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The folder models/pyfunc_gm_model_0 does not exist or is not a valid directory.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "068cd1d1e5654d6ab541a85554a82aa0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/17 20:46:46 INFO mlflow.tracking._tracking_service.client: üèÉ View run clumsy-frog-615 at: https://dagshub.com/micheldpd24/mlflow_tracking.mlflow/#/experiments/11/runs/4681a737b4d24117951ad34417553082.\n",
      "2024/11/17 20:46:46 INFO mlflow.tracking._tracking_service.client: üß™ View experiment at: https://dagshub.com/micheldpd24/mlflow_tracking.mlflow/#/experiments/11.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logged model for alternative: 0\n",
      "The folder models/pyfunc_gm_model_1 does not exist or is not a valid directory.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9020f85914db4727a72443079d53962d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logged model for classical: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/17 20:46:56 INFO mlflow.tracking._tracking_service.client: üèÉ View run blushing-lamb-393 at: https://dagshub.com/micheldpd24/mlflow_tracking.mlflow/#/experiments/12/runs/97415837942749379345006f19971a32.\n",
      "2024/11/17 20:46:56 INFO mlflow.tracking._tracking_service.client: üß™ View experiment at: https://dagshub.com/micheldpd24/mlflow_tracking.mlflow/#/experiments/12.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The folder models/pyfunc_gm_model_2 does not exist or is not a valid directory.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d73dc5e75824febb59f15354c2b8655",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logged model for country: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/17 20:47:11 INFO mlflow.tracking._tracking_service.client: üèÉ View run respected-shark-469 at: https://dagshub.com/micheldpd24/mlflow_tracking.mlflow/#/experiments/13/runs/d9fc74043f73455f8f6335e2cf9cabe3.\n",
      "2024/11/17 20:47:11 INFO mlflow.tracking._tracking_service.client: üß™ View experiment at: https://dagshub.com/micheldpd24/mlflow_tracking.mlflow/#/experiments/13.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The folder models/pyfunc_gm_model_3 does not exist or is not a valid directory.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "963153912ee64a25aec56079030b2f45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logged model for edm: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/17 20:47:26 INFO mlflow.tracking._tracking_service.client: üèÉ View run stylish-trout-626 at: https://dagshub.com/micheldpd24/mlflow_tracking.mlflow/#/experiments/14/runs/790370eb496e41df9f762743b99077f6.\n",
      "2024/11/17 20:47:26 INFO mlflow.tracking._tracking_service.client: üß™ View experiment at: https://dagshub.com/micheldpd24/mlflow_tracking.mlflow/#/experiments/14.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The folder models/pyfunc_gm_model_4 does not exist or is not a valid directory.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "965cf5b0e1ea4805aea089a319632f24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logged model for hip-hop: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/17 20:47:41 INFO mlflow.tracking._tracking_service.client: üèÉ View run popular-shark-106 at: https://dagshub.com/micheldpd24/mlflow_tracking.mlflow/#/experiments/15/runs/f47e3d84fff949b39ba6de4204cf0f4c.\n",
      "2024/11/17 20:47:41 INFO mlflow.tracking._tracking_service.client: üß™ View experiment at: https://dagshub.com/micheldpd24/mlflow_tracking.mlflow/#/experiments/15.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The folder models/pyfunc_gm_model_5 does not exist or is not a valid directory.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "172d619b59164d859b12a06f39fbcff0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logged model for jazz: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/17 20:47:56 INFO mlflow.tracking._tracking_service.client: üèÉ View run kindly-crow-58 at: https://dagshub.com/micheldpd24/mlflow_tracking.mlflow/#/experiments/16/runs/f3de68727af944478e75695b681197e8.\n",
      "2024/11/17 20:47:56 INFO mlflow.tracking._tracking_service.client: üß™ View experiment at: https://dagshub.com/micheldpd24/mlflow_tracking.mlflow/#/experiments/16.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The folder models/pyfunc_gm_model_6 does not exist or is not a valid directory.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08587cc924c143e4bd1db899a7c63df2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logged model for latin: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/17 20:48:11 INFO mlflow.tracking._tracking_service.client: üèÉ View run welcoming-zebra-640 at: https://dagshub.com/micheldpd24/mlflow_tracking.mlflow/#/experiments/17/runs/138b73f5fc804df7838d383a838e07ae.\n",
      "2024/11/17 20:48:11 INFO mlflow.tracking._tracking_service.client: üß™ View experiment at: https://dagshub.com/micheldpd24/mlflow_tracking.mlflow/#/experiments/17.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The folder models/pyfunc_gm_model_7 does not exist or is not a valid directory.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae50a242464849b5928a8c25e63a2e41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logged model for pop: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/17 20:48:26 INFO mlflow.tracking._tracking_service.client: üèÉ View run big-loon-596 at: https://dagshub.com/micheldpd24/mlflow_tracking.mlflow/#/experiments/18/runs/c95fd747f41047f495d8c34ba936bb85.\n",
      "2024/11/17 20:48:26 INFO mlflow.tracking._tracking_service.client: üß™ View experiment at: https://dagshub.com/micheldpd24/mlflow_tracking.mlflow/#/experiments/18.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The folder models/pyfunc_gm_model_8 does not exist or is not a valid directory.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47361dfe2ddb4f32b7675af79da49332",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logged model for r-n-b: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/17 20:48:41 INFO mlflow.tracking._tracking_service.client: üèÉ View run wistful-bass-410 at: https://dagshub.com/micheldpd24/mlflow_tracking.mlflow/#/experiments/19/runs/92ccefc1efd842c99d0ccd215fdb4153.\n",
      "2024/11/17 20:48:41 INFO mlflow.tracking._tracking_service.client: üß™ View experiment at: https://dagshub.com/micheldpd24/mlflow_tracking.mlflow/#/experiments/19.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The folder models/pyfunc_gm_model_9 does not exist or is not a valid directory.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35d810c107a94473acb810c034265dbd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logged model for rock: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/17 20:48:56 INFO mlflow.tracking._tracking_service.client: üèÉ View run rumbling-smelt-628 at: https://dagshub.com/micheldpd24/mlflow_tracking.mlflow/#/experiments/20/runs/d8e05924f82a4ffdb13665220a7a8c01.\n",
      "2024/11/17 20:48:56 INFO mlflow.tracking._tracking_service.client: üß™ View experiment at: https://dagshub.com/micheldpd24/mlflow_tracking.mlflow/#/experiments/20.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Run ID: 4681a737b4d24117951ad34417553082\n",
      "Best Silhouette_score: 0.5495264854082571\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13909ebbba1d42959fde67c5f3046d4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best clst_0_alternative model loaded successfully!\n",
      "The folder models_best/pyfunc_clst_0_alternative_model does not exist or is not a valid directory.\n",
      "Best Run ID: 97415837942749379345006f19971a32\n",
      "Best Silhouette_score: 0.5490066926843931\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c15ad2a4f1504badb9446ee92078653a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best clst_1_classical model loaded successfully!\n",
      "The folder models_best/pyfunc_clst_1_classical_model does not exist or is not a valid directory.\n",
      "Best Run ID: d9fc74043f73455f8f6335e2cf9cabe3\n",
      "Best Silhouette_score: 0.5560450067624154\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b32472f150784e07a294c19ecf1da258",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best clst_2_country model loaded successfully!\n",
      "The folder models_best/pyfunc_clst_2_country_model does not exist or is not a valid directory.\n",
      "Best Run ID: 790370eb496e41df9f762743b99077f6\n",
      "Best Silhouette_score: 0.5882012550391456\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac86189e9ded40d0b1474989dd515f6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best clst_3_edm model loaded successfully!\n",
      "The folder models_best/pyfunc_clst_3_edm_model does not exist or is not a valid directory.\n",
      "Best Run ID: f47e3d84fff949b39ba6de4204cf0f4c\n",
      "Best Silhouette_score: 0.5758989107410665\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef81364520f747e2926415d17b3e9e4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best clst_4_hip-hop model loaded successfully!\n",
      "The folder models_best/pyfunc_clst_4_hip-hop_model does not exist or is not a valid directory.\n",
      "Best Run ID: f3de68727af944478e75695b681197e8\n",
      "Best Silhouette_score: 0.5766833876471491\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80714d8733d241b59947aa94150e6d6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best clst_5_jazz model loaded successfully!\n",
      "The folder models_best/pyfunc_clst_5_jazz_model does not exist or is not a valid directory.\n",
      "Best Run ID: 138b73f5fc804df7838d383a838e07ae\n",
      "Best Silhouette_score: 0.6589549301935923\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8503881ad8ec46c9829bddd7889985ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best clst_6_latin model loaded successfully!\n",
      "The folder models_best/pyfunc_clst_6_latin_model does not exist or is not a valid directory.\n",
      "Best Run ID: c95fd747f41047f495d8c34ba936bb85\n",
      "Best Silhouette_score: 0.5684911205654885\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d742f5c09f1849a1a67c1518fdc4877f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best clst_7_pop model loaded successfully!\n",
      "The folder models_best/pyfunc_clst_7_pop_model does not exist or is not a valid directory.\n",
      "Best Run ID: 92ccefc1efd842c99d0ccd215fdb4153\n",
      "Best Silhouette_score: 0.5489443609907552\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b26d924d56b4a5880a5e25e8be29805",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best clst_8_r-n-b model loaded successfully!\n",
      "The folder models_best/pyfunc_clst_8_r-n-b_model does not exist or is not a valid directory.\n",
      "Best Run ID: d8e05924f82a4ffdb13665220a7a8c01\n",
      "Best Silhouette_score: 0.533007744907941\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c4e23d38b154cd2801ab67776d85215",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best clst_9_rock model loaded successfully!\n",
      "The folder models_best/pyfunc_clst_9_rock_model does not exist or is not a valid directory.\n"
     ]
    }
   ],
   "source": [
    "config = ConfigurationManager()\n",
    "unsmodel_fit_config = config.get_unsmodel_fit_config()\n",
    "unsmodel_fit = UnsModelFit(config= unsmodel_fit_config)\n",
    "unsmodel_fit.unsfit()\n",
    "unsmodel_fit.get_best_clst_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find and register the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # function to find and load the best model\n",
    "\n",
    "# import mlflow\n",
    "# from mlflow.tracking import MlflowClient\n",
    "\n",
    "# def load_best_model_from_experiment(experiment_name: str = \"music_clf\", model: str = \"GB_model\", metric: str = \"accuracy\"):\n",
    "#     \"\"\"\n",
    "#     Retrieves the MLflow run with the best score for a specified metric and loads the associated model.\n",
    "    \n",
    "#     Args:\n",
    "#         experiment_name (str): The name of the MLflow experiment.\n",
    "#         metric (str): The metric used to determine the best model. Default is \"accuracy\".\n",
    "    \n",
    "#     Returns:\n",
    "#         tuple: A tuple containing:\n",
    "#             - loaded_model: The MLflow model object.\n",
    "#             - best_run_id (str): The ID of the best run.\n",
    "#             - best_metric_value (float): The value of the best metric.\n",
    "    \n",
    "#     Raises:\n",
    "#         ValueError: If the experiment or runs are not found.\n",
    "#     \"\"\"\n",
    "#     # Initialize the MLflow client\n",
    "#     client = MlflowClient()\n",
    "    \n",
    "#     # Get the experiment details\n",
    "#     experiment = client.get_experiment_by_name(experiment_name)\n",
    "#     if not experiment:\n",
    "#         raise ValueError(f\"Experiment '{experiment_name}' not found!\")\n",
    "    \n",
    "#     # Fetch all runs for the experiment\n",
    "#     runs = client.search_runs(\n",
    "#         experiment_ids=[experiment.experiment_id],\n",
    "#         filter_string=\"\",\n",
    "#         run_view_type=mlflow.entities.ViewType.ACTIVE_ONLY,\n",
    "#         order_by=[f\"metrics.{metric} DESC\"]  # Order by the specified metric in descending order\n",
    "#     )\n",
    "    \n",
    "#     if not runs:\n",
    "#         raise ValueError(f\"No runs found for experiment '{experiment_name}'!\")\n",
    "    \n",
    "#     # Extract the best run\n",
    "#     best_run = runs[0]\n",
    "#     best_run_id = best_run.info.run_id\n",
    "#     best_metric_value = best_run.data.metrics[metric]\n",
    "    \n",
    "#     print(f\"Best Run ID: {best_run_id}\")\n",
    "#     print(f\"Best {metric.capitalize()}: {best_metric_value}\")\n",
    "    \n",
    "#     # Load the model associated with the best run\n",
    "#     model_uri = f\"runs:/{best_run_id}/{model}\"\n",
    "#     loaded_model = mlflow.pyfunc.load_model(model_uri)\n",
    "    \n",
    "#     print(f\"Best {experiment_name} model loaded successfully!\")\n",
    "\n",
    "#     return loaded_model, best_run_id, best_metric_value\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find best GM clustering model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# from joblib import dump\n",
    "# genres = load_txt(Path(\"data/to_rec/genres.txt\"))\n",
    "# for element, genre in enumerate(genres):\n",
    "#     experiment_name = f\"clst_{element}_{genre}\"\n",
    "#     model = \"GM_model\"\n",
    "#     metric = \"silhouette_score\"\n",
    "#     loaded_model, best_run_id, best_metric_value = load_best_model_from_experiment(experiment_name, model, metric)\n",
    "#     mlflow.sklearn.save_model(loaded_model, f\"models_best/gm_model_{element}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find the best GB classifier model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loaded_model, best_run_id, best_metric_value = load_best_model_from_experiment(experiment_name=\"music_clf\", model=\"GB_model\", model_name=\"GB_CLF\", metric=\"accuracy\")\n",
    "# mlflow.sklearn.save_model(loaded_model,f\"models_best/gb_model\" )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
